---
title: "Biostat 203B Homework 2"
subtitle: Due Feb 10 @ 11:59PM
author: Olivia Golston
output: 
  html_document:
    toc: true
    toc_depth: 4 
---

Display machine information for reproducibility:
```{r}
sessionInfo()
```

```{r setup}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(tidyverse)
library(data.table)
library(lubridate)
```

```{r}
os <- sessionInfo()$running
if (str_detect(os, "Linux")) {
  mimic_path <- "/usr/203b-data/mimic-iv"
} else if (str_detect(os, "macOS")) {
  mimic_path <- "/Users/huazhou/Documents/Box Sync/MIMIC/mimic-iv-0.4"
}
```

Use tidyverse (ggpot2, dplyr) to explore the [MIMIC-IV](https://mimic-iv.mit.edu) data introduced in [homework 1](https://ucla-biostat203b-2021winter.github.io/hw/hw1/hw1.html).

```{r}
system(str_c("tree -s -L 2 ", shQuote(mimic_path)), intern = TRUE)
```

## Q1. PhysioNet credential

At this moment, you should already get credentialed on the PhysioNet. Please include a screenshot of your `Data Use Agreement for the MIMIC-IV (v0.4)`.

### Solution

![Screenshot of data use agreement](agreement.png)



## Q2. `read.csv` (base R) vs `read_csv` (tidyverse) vs `fread` (data.table)

There are quite a few utilities in R for reading data files. Let us test the speed of reading a moderate sized compressed csv file, `admissions.csv.gz`, by three programs: `read.csv` in base R, `read_csv` in tidyverse, and `fread` in the popular data.table package. Is there any speed difference?

In this homework, we stick to the tidyverse. 

### Solution

The code below records the time required to read in `admissions.csv.gz`. 
```{r message=F}
file_path <- str_c(mimic_path, "/core/admissions.csv.gz")

time1 <- system.time(file1 <- read.csv(file_path))
time2 <- system.time(file2 <- read_csv(file_path))
time3 <- system.time(file3 <- fread(file_path))

```

A comparison of elapsed times are displayed in the table.

Function | Time Elapsed for Execution
-------- | -------------
read.csv | `r time1[3]` 
read_csv | `r time2[3]`
fread    | `r time3[3]`

`read.csv` seems to be the slowest, by far. `read_csv` and `fread` are similar, but `fread` tends to be a slight bit faster.


Memory is an issue for this assignment, so these variables are removed from the environment.
```{r}
rm(file1)
rm(file2)
rm(file3)

rm(time1)
rm(time2)
rm(time3)
```


## Q3. ICU stays

`icustays.csv.gz` (<https://mimic-iv.mit.edu/docs/datasets/icu/icustays/>) contains data about Intensive Care Units (ICU) stays. Summarize following variables using appropriate numerics or graphs:   

- how many unique `stay_id`?  
- how many unique `subject_id`?  
- length of ICU stay  
- first ICU unit  
- last ICU unit  

### Solution

First, read in `icustays` data and view the first 10 observations. 
```{r}
icu_stays <- read_csv(str_c(mimic_path, "/icu/icustays.csv.gz")) 

icu_stays %>%
  print()
``` 

Check number of unique `stay_id` values:
```{r}
icu_stays %>% 
  distinct(stay_id) %>%
  nrow()
```
There are 69,619 unique `stay_id` values. This is equal to the number of observations in the original data set, because each observation has been assigned a unique `stay_id` value.  


Check number of unique `subject_id` values:
```{r}
icu_stays %>%
  distinct(subject_id) %>%
  nrow()
```
There are 50048 unique `subject_id` values. This is less than the total number of observations, which means that some individuals have had multiple ICU stays, and are present two or more times in the data.  

```{r}
icu_stays %>%
  count(subject_id) %>%
  rename(number_of_stays = n) %>%
  count(number_of_stays) %>% 
  rename(number_of_patients = n) %>%
  arrange(desc(number_of_stays)) %>% 
  print()
```
One patient has had 33 ICU stays! However, the majority of patients have a count of 1, 2, or 3 stays.


Visualize length of stay, which is coded as the the `los` variable. In my initial plot, it appeared that the mass of observations had short stays (less than 30 days), but there were a few extreme outlying values that made the plot hard to interpret. I want to see how common these long stays are. 
```{r}
icu_stays %>%
  filter(los >= 50) %>%
  arrange(desc(los)) %>%
  select(los)
```
Out of over 69,000 observations, only 112 had stays of 50 days or longer, and only 11 had stays of 100 days or longer. 

To make the graph more interpretable, I decided to exclude these outlying values. They should not be forgotten, but do not represent a typical ICU stay. 
```{r}
icu_stays %>%
  ggplot(aes(x = los)) +
  geom_histogram(binwidth = .5) +
  coord_cartesian(xlim = c(0,50)) +
  labs(title = "Distribution of Length of Stay (extreme values excluded)", 
       x = "Length of Stay (days)")
```
It appears that most people stay in the ICU for less than 5 days, and very few stay beyond 10. 


`first_careunit`
```{r}
icu_stays %>%
  ggplot(aes(x = first_careunit)) +
  geom_bar() +
  coord_flip() +
  labs(x = "First Care Unit", title = "First Care Unit during ICU Stay")
```


`last_careunit`
```{r}
icu_stays %>%
  ggplot(aes(x = last_careunit)) +
  geom_bar() +
  coord_flip() +
  labs(x = "Last Care Unit", title = "Last Care Unit during ICU Stay")
```






## Q4. `admission` data

Information of the patients admitted into hospital is available in `ADMISSION.csv.gz`. See <https://mimic-iv.mit.edu/docs/datasets/core/admissions/> for details of each field in this file. Summarize following variables using appropriate graphs. Explain any patterns you observe.   

- admission year  
- admission month  
- admission month day  
- admission week day  
- admission hour (anything unusual?)  
- number of deaths in each year  
- admission type  
- number of admissions per patient  
- admission location  
- discharge location  
- insurance  
- language  
- martial status  
- ethnicity  
- death 

Note it is possible that one patient (uniquely identified by the `SUBJECT_ID`) is admitted into hospital multiple times. When summarizing some demographic information, it makes sense to summarize based on unique patients. 

### Solution
First, we need to read in the admissions data. This dataset will have all admissions.
```{r}
admissions <- read_csv(str_c(mimic_path, "/core/admissions.csv.gz")) 

admissions %>%
  print()
``` 

We also want a filtered version of the data that only contains unique patients, as identified by subject_id.
```{r}
admissions_unique <- admissions %>%
  distinct(subject_id, .keep_all = TRUE) 

admissions_unique %>% 
  print()
```


- admission year  
```{r}
ggplot(data = admissions) +
  geom_bar(aes(year(admittime)))
```


- admission month  
```{r}
ggplot(data = admissions) +
  geom_bar(aes(month(admittime, label = T))) +
  labs(title = "Admissions by Month", x = "Month")
```



- admission month day 
```{r}
ggplot(data = admissions) +
  geom_bar(aes(day(admittime))) +
  labs(title = "Admissions by Day of Month", x = "Day of Month")
```


- admission week day  
```{r}
ggplot(data = admissions) +
  geom_bar(aes(wday(admittime, label = T))) +
  labs(title = "Admissions by Day of Week", x = "Day of Week")
```

- admission hour (anything unusual?)  
```{r}
ggplot(data = admissions) +
  geom_bar(aes(hour(admittime))) +
  labs(title = "Admissions by Hour", x = "Hour")
```

- number of deaths in each year  
```{r}
admissions %>%
  filter(!is.na(deathtime)) %>%
  ggplot() +
  geom_bar(aes(year(deathtime)))
```



- admission type  
```{r}
admissions %>%
  ggplot() +
  geom_bar(aes(admission_type)) +
  coord_flip() +
  labs(x = "Admissions Type")
```

- number of admissions per patient  
```{r}
admissions %>%
  count(subject_id) %>%
  ggplot() +
  geom_bar(aes(n)) 
```


- admission location  
```{r}
admissions %>%
  ggplot() +
  geom_bar(aes(admission_location)) +
  coord_flip() +
  labs(x = "Admission Location")
```


- discharge location  
```{r}
admissions %>%
  ggplot() +
  geom_bar(aes(discharge_location)) +
  coord_flip() +
  labs(x = "Discharge Location")
```


- insurance  
```{r}
admissions_unique %>% 
  ggplot() +
  geom_bar(aes(insurance))
```



- language  
```{r}
admissions_unique %>% 
  ggplot() +
  geom_bar(aes(language))
```

- martial status
```{r}
admissions_unique %>% 
  ggplot() +
  geom_bar(aes(marital_status))

```

- ethnicity  
```{r}
admissions_unique %>% 
  ggplot() +
  geom_bar(aes(ethnicity)) +
  coord_flip()
```

- death 
```{r}
admissions %>% 
  group_by(subject_id) %>%
  count(died = sum(!(is.na(deathtime))) > 0) %>%
  ggplot() +
  geom_bar(aes(died))

colnames(admissions_unique)
```

## Q5. `patient` data

Explore `patients.csv.gz` (<https://mimic-iv.mit.edu/docs/datasets/core/patients/>) and summarize following variables using appropriate numerics and graphs:  

- `gender`  
- `anchor_age` (explain pattern you see)

```{r}
patients <- read_csv(str_c(mimic_path, "/core/patients.csv.gz")) 


patients %>%
  print(width = Inf)
```


```{r}
patients %>%
  ggplot(aes(x = factor(1), fill = gender)) +
    geom_bar(width=1) +
    coord_polar("y") +
    labs(x = "Gender")
```


```{r}
patients %>%
  ggplot() +
    geom_bar(aes(anchor_age)) 
```
There is a huge spike at 0, and then no observations until ~age 18. Thus, my best guess is that the age of minors is not recorded, to protect privacy. Instead, they all recieve the age "0." After age 18, the ages appear to be coded as normal.  However, there is another spike at the upper end. Perhaps the system can't keep track of 3 digits for age, or they want to protect the privacy of their oldest patients by grouping their ages. 



## Q6. Lab results

`labevents.csv.gz` (<https://mimic-iv.mit.edu/docs/datasets/hosp/labevents/>) contains all laboratory measurements for patients. 

We are interested in the lab measurements of creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), glucose (50931), magnesium (50960), calcium (50893), and lactate (50813). Find the `itemid`s of these lab measurements from `d_labitems.csv.gz` and retrieve a subset of `labevents.csv.gz` only containing these items.

### Solution
This question was tricky, since the `labevents.csv.gz` file is so large.
```{bash eval = F}
zcat /usr/203b-data/mimic-iv/hosp/labevents.csv.gz | wc -l
```
The file has 122,289,829 lines. Trying to read this in caused RStudio to crash. Thus, a filtered version of the file was created by Dr. Zhou. 


```{bash eval = F}
zcat /usr/203b-data/mimic-iv-derived-data/labevents_filtered_itemid.csv.gz | 
  wc -l
```
This filtered file has 30,773,355 lines and contains only the variables of interest.



#### The Process I would have used
Due to the technical issues described above, it was not possible to complete the problem as originally assigned. However, below is the code that could have been used to find the `itemids` for the lab measurements of interest, and to filter the dataset to contain only those measurements. 

First, load the dictionary file, which has information about the various lab measurements:
```{r}
labcodes <- read_csv(str_c(mimic_path, "/hosp/d_labitems.csv.gz")) %>%
  print(width = Inf) 
```

Search for key terms in the `label` column to find the lab measurement of interest. For example, creatinine: 
```{r}
creatinine_items <- labcodes %>%
  filter(str_detect(label, regex("Creatinine", ignore_case = TRUE))) %>%
  print()
``` 
Since there are so many creatinine related measurements, it may make sense to filter this list further, especially to make our final dataset more manageable. First we create a vector of all `itemid` values associated with creatinine.

```{r}
creatinine_ids <- creatinine_items %>%
  .$itemid %>% 
  print()
```

Assuming the `labevents` file had been successfully read into a tibble called `labs`, we can now see which creatinine `itemid` appers most frequently. The following code filters to only the lab events related to creatinine, counts the times each `itemid` appears, orders from highest to lowest count, and then saves and prints the top occuring `itemid`. For creatinine, this is 50912.
```{r eval = F}
top_creatinine_id <- labs %>%
  filter(itemid %in% creatinine_ids) %>%
  count(itemid) %>%
  arrange(desc(n)) %>%
  slice(1) %>%
  .$itemid %>%
  print()
```

This process could be repeated for the other requested lab items. Dr. Zhou provided the `itemids` for the all measurements. These can be used to filter down the `labcodes` frame.
```{r}
lab_ids <- labcodes %>%
  filter(itemid %in% c("50912", "50971", "50983", "50902", "50882", "51221", 
                      "51301", "50931", "50960", "50893", "50813")) %>%
  select(itemid, label) %>%
  print()

```


Finally, the `labs` data can be filtered down to only these measurements of interest.
```{r eval=F}
labs <- labs %>%
  filter(itemid %in% lab_ids$itemid) %>%
  print()
```


#### Reading in the filtered file

Dr. Zhou conducted the above steps to obtain the list of `itemid` values of interest. Then, using `awk` in bash, he filtered only rows with the `itemid` values of interest, and kept only the variables of interest. 

The resulting dataset was read in and saved using the following code. `charttime` was saved as a date variable, since `fread` was parsing it as a character. 
```{r eval = F}
derived_data_path <- "/usr/203b-data/mimic-iv-derived-data"

if(!file.exists("labevents_filtered.csv.gz")) {
    labevents_tble <- fread(str_c(derived_data_path, 
                                  "/labevents_filtered_itemid.csv.gz"),
                          header = FALSE,
                          col.names = c("subject_id", 
                                        "hadm_id",
                                        "itemid", 
                                        "charttime", 
                                        "valuenum"),
                          nThread = 4) %>%
    as_tibble() %>%
    mutate_at(c("subject_id", "hadm_id", "itemid"), as.numeric) %>%
    mutate(charttime = ymd_hms(charttime)) 
    
    labevents_tble %>%
      fwrite("labevents_filtered.csv.gz", nThread = 4)
} 

```

Can uncomment the below code to read in the data.
```{r eval = F}
#labs <- fread("labevents_filtered.csv.gz", nThread = 1)
```




Since memory is an issue, I remove unnecessary data from the environment, such as the full lab codes dictionary and the demonstration data frames for creatinine.
```{r}
rm(labcodes)
rm(creatinine_items)
rm(creatinine_ids)
```

## Q7. Vitals from chartered events

We are interested in the vitals for ICU patients: heart rate, mean and systolic blood pressure (invasive and noninvasive measurements combined), body temperature, SpO2, and respiratory rate. Find the `itemid`s of these vitals from `d_items.csv.gz` and retrieve a subset of `chartevents.csv.gz` only containing these items.

`chartevents.csv.gz` (<https://mimic-iv.mit.edu/docs/datasets/icu/chartevents/>) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patientâ€™s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`.


`d_items.csv.gz` (<https://mimic-iv.mit.edu/docs/datasets/icu/d_items/>) is the dictionary for the `itemid` in `chartevents.csv.gz`. 

### Solution

As with `labevents.csv.gz`, the `chartevents.csv.gz` file is massive. 
```{bash eval = F}
zcat /usr/203b-data/mimic-iv/icu/chartevents.csv.gz | wc -l
```
The original file has 327,363,275 lines and can not be read into RStudio easily. Thus, a filtered version of the file was created by Dr. Zhou. 


```{bash eval = F}
zcat /usr/203b-data/mimic-iv-derived-data/chartevents_filtered_itemid.csv.gz | 
  wc -l
```
The filtered file has 30,095,996 lines and is easier to work with.


#### The Process I would have used

As before, the problem could not be completed as initially intended. However, a similar process to that described in Question 6 would have been used to get the final filtered version of the dataset.  


First, read in the dictionary file for chart items: 
```{r}
chart_codes <- read_csv(str_c(mimic_path, "/icu/d_items.csv.gz")) %>%
  print(width = Inf) 
```

Search for key terms in the `label` column to find the lab measurement of interest. For example, to search for heart rate, view the corresponding chart items, and get a vector of `itemid` values: 
```{r}
measurements <- c("heart rate", "blood pressure mean", "systolic", 
                  "temperature", "SpO2", "respiratory rate")

for (item in measurements) {
  chart_codes %>%
    filter(str_detect(label, regex(item, ignore_case = T))) %>%
    print()
}

```
We can inspect the output and choose which measurement seems the most reasonable to keep  However, if there is any doubt about which `itemid` to use, we use a similar process to what was done in Q6. 


Once this process has been repeated for all measurements of interest, and desired `itemid` values have been saved into vector `top_ids`, the `chart_events` data can be filtered to contain only the subset of desired measurements.

```{r eval=F}
chart_events <- chart_events %>%
  filter(itemid %in% top_ids %>%
  print()
```


#### Reading in the filtered file

As with the `labevents` data, Dr. Zhou did the steps outlined above but used `awk` to select only the necessary columns and rows of the `chartevents` data. This pre-filtered file, `chartevents_filtered.csv.gz`, was read in and saved. 
```{r eval = F}
if(!file.exists("chartevents_filtered.csv.gz")) {
    chartevents_tble <- fread(str_c(derived_data_path, 
                                    "/chartevents_filtered_itemid.csv.gz"),
                          header = FALSE,
                          col.names = c("subject_id",
                                       "hadm_id",
                                       "stay_id",
                                       "charttime",
                                       "itemid",
                                       "valuenum"),
                          nThread = 4) %>%
    as_tibble() %>%
    mutate_at(c("subject_id", "hadm_id", "stay_id", "itemid"), as.numeric) %>%
    mutate(charttime = ymd_hms(charttime)) %>%
    print(width = Inf)
    
    chartevents_tble %>%
      fwrite("chartevents_filtered.csv.gz", nThread = 4)
    
} 
```

Can uncomment the below code to read this in. 
```{r eval = F}
#chart_events <- fread("chartevents_filtered.csv.gz", nThread = 1)
```

This code chunk has a reduced file that I will create in Q8. 
```{r}
chart_events <- fread("chartevents_filtered_icustays.csv.gz", nThread = 1)
```


I want to see what codes Dr. Zhou selected. 
```{r}
chart_events %>%
  group_by(itemid) %>%
  count()
```

The codes are: 220045, 220050, 220052, 220179, 220181, 220210, 223761.

I want to see what these correspond to and save the results.
```{r}
chart_ids <- chart_codes %>%
  filter(itemid %in% c("220045", "220050", "220052", 
                       "220179", "220181", "220210", "223761")) %>%
  select(itemid, label) %>%
  print()

```


Remove unnecessary data from environment:
```{r}
rm(chart_codes)
rm(measurements)
```

## Q8. Putting things together

Let us create a tibble for all ICU stays, where rows are  

- first ICU stay of each unique patient  
- adults (age at admission > 18)  

and columns contain at least following variables  

- all variables in `icustays.csv.gz`  
- all variables in `admission.csv.gz`  
- all variables in `patients.csv.gz`  
- first lab measurements during ICU stay  
- first vitals measurement during ICU stay  
- an indicator variable whether the patient died within 30 days of hospital admission  


### Solution

The "base" data for this problem is the ICU data, which I stored in the data frame `icu_stays` in Question 3. The first goal is to keep only the first ICU stay for each patient, which can be done by grouping by `subject_id` and then keeping only the first chronological stay. 
```{r}
full_icu_tibble <- icu_stays %>%
  group_by(subject_id) %>%
  filter(rank(intime) == 1) %>%
  ungroup()
```

Next, we join to the `admissions` (created in Q4) and `patients` (from Q5): The ICU stay can be joined to `admissions` by `hadm_id` (we also use `subject_id`, but it's not strictly necessary), and can be joined to `patients` by `subject_id`.
```{r}
full_icu_tibble <- full_icu_tibble %>%
  left_join(admissions, by = c("hadm_id", "subject_id")) %>% 
  left_join(patients, by = c("subject_id")) %>%
  print()
```

Now, we want to keep only adults. Since the only age recorded is the age during the "anchor year", we need to calculate what the age at time of the admission was.  We do this by finding how many years have passed since the `anchor_year` and adding those to the `anchor_age`. Then, we filter such that only adults (> 18) are kept. 
```{r}
full_icu_tibble <- full_icu_tibble %>%
  mutate(age_at_adm = year(admittime) - anchor_year + anchor_age) %>%
  filter(age_at_adm > 18) %>% 
  print()
```
There are 49,971 unique adults with ICU stays.



Now, we want to merge lab results to this table. However, we only want to keep the first lab result of each type, during the ICU stay.

The filtered `labevents` file is still huge, so now is a convenient time to save a version that keeps only observations that will be used for this final step.
```{r}
if(!file.exists("labevents_filtered_icustays.csv.gz")) {
  labs %>%
    semi_join(full_icu_tibble, by = c("subject_id", "hadm_id")) %>%
    fwrite("labevents_filtered_icustays.csv.gz", nThread = 4)
}
```


```{r}
labs <- fread("labevents_filtered_icustays.csv.gz", nThread = 1)
```


```{r}
full_icu_labs <- labs %>%
  semi_join(full_icu_tibble, by = c("subject_id", "hadm_id")) %>%
  left_join(select(full_icu_tibble, subject_id, hadm_id, intime), 
                   by = c("subject_id", "hadm_id")) %>%
  filter(charttime >= intime) %>%
  group_by(subject_id, itemid) %>%
  arrange(charttime, .by_group = TRUE) %>%   #sort within each group 
  slice_head(n = 1) %>%   
  select(-charttime, -intime) %>%
  spread(key = itemid, value = valuenum) %>%
  right_join(full_icu_tibble, by = c("subject_id", "hadm_id")) %>%
  ungroup() %>%
  rename_at(vars(as.character(lab_ids$itemid)), ~lab_ids$label) %>%
  print()
```

```{r}
rm(labs)
```

We'll follow a similar pattern for chart events. First, it's convenient to save a version with only adults in the ICU data.
```{r}
if(!file.exists("chartevents_filtered_icustays.csv.gz")) {
  chart_events %>%
    semi_join(full_icu_tibble, by = c("subject_id", "hadm_id")) %>%
    fwrite("chartevents_filtered_icustays.csv.gz", nThread = 4)
}
```

```{r}
chart_events <- fread("chartevents_filtered_icustays.csv.gz", nThread = 1)
```

Now, we repeat the same process as above. Notice that we now have two tibbles: `full_icu_labs` and `full_icu_chart`.  Also, rather than `hadm_id`, `stay_id` is the unique identifier for the chart events. 
```{r}
full_icu_chart <- chart_events %>%
  semi_join(full_icu_tibble, by = c("subject_id", "stay_id")) %>%
  left_join(select(full_icu_tibble, subject_id, stay_id, intime), 
                   by = c("subject_id", "stay_id")) %>%
  filter(charttime >= intime) %>%
  group_by(subject_id, itemid) %>%
  arrange(charttime, .by_group = TRUE) %>%   #sort within each group 
  slice_head(n = 1) %>%   
  select(-charttime, -intime) %>%
  spread(key = itemid, value = valuenum) %>%
  right_join(full_icu_tibble, by = c("subject_id", "hadm_id")) %>%
  ungroup() %>%
  rename_at(vars(as.character(chart_ids$itemid)), ~chart_ids$label) %>%
  print()


rm(chart_events)
```

Left join by all matching variables in the data, since they should match between the two datasets.
```{r} 
final_icu_data <- full_icu_labs %>%
  left_join(full_icu_chart) %>% 
  print(width = Inf)
```

Many intermediate data frames are no longer needed.
```{r}
rm(full_icu_chart)
rm(full_icu_labs)
rm(full_icu_tibble)
```


The final step is determining whether the patient died within 30 days of hospital admission.
```{r}
final_icu_data <- final_icu_data %>%
  mutate(time_to_death = as.duration(deathtime - intime),
         death_in_30 = ifelse(is.na(time_to_death) | time_to_death > ddays(30), 
                                    FALSE, TRUE)) %>%
  select(-time_to_death) %>%
  print()
```

How many people die within 30 days?
```{r}
final_icu_data %>%
  filter(death_in_30) %>%
  count()
```
Of the 49,971 admissions, 4974 individuals die within 30 days. 


How many patients die, but after 30 days?
```{r}
final_icu_data %>%
  filter(!is.na(deathtime) & !death_in_30) %>%
  count()
```
201 people die after the 30 day mark. 